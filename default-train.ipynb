{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setup the kaggle environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!git clone https://github.com/benihime91/leaf-disease-classification-kaggle.git\n!pip install hydra-core timm --upgrade --quiet\n\nimport sys\nsys.path.append(\"/kaggle/working/leaf-disease-classification-kaggle/\")","execution_count":2,"outputs":[{"output_type":"stream","text":"Cloning into 'leaf-disease-classification-kaggle'...\nremote: Enumerating objects: 289, done.\u001b[K\nremote: Counting objects: 100% (289/289), done.\u001b[K\nremote: Compressing objects: 100% (204/204), done.\u001b[K\nremote: Total 289 (delta 142), reused 196 (delta 66), pack-reused 0\u001b[K\nReceiving objects: 100% (289/289), 8.38 MiB | 10.66 MiB/s, done.\nResolving deltas: 100% (142/142), done.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Import depedencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom experiment import run\nfrom hydra.experimental import initialize, initialize_config_module, initialize_config_dir, compose\nfrom omegaconf import OmegaConf\nimport time","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setting up the config pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting up config paths\nconfig_dir = \"/kaggle/working/leaf-disease-classification-kaggle/conf/\"\nconfig_name = \"config\"\nmodel_arch = \"efficientnetb0\"\n\n# which fold to train on ?\nfold_num = 0 \n\n# setting up the configuration\n# see: https://hydra.cc/docs/next/advanced/override_grammar/basic/\nimage_dir = \"/kaggle/input/cassava-leaf-disease-classification/train_images/\"\ncsv_dir   = \"/kaggle/input/cassava-leaf-disease-classification/train.csv\"\njson_dir  = \"/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json\"\nfold_csv_dir = \"/kaggle/working/leaf-disease-classification-kaggle/data/fold_df.csv\"\n\n# setting up model save paths and job_name\nrun_name = f\"{model_arch}_fold_{fold_num}_{int(time.time())}\"\ncheckpoint_path = \"/kaggle/working/\"\nmodel_save_dir = f\"/kaggle/working/{model_arch}_fold_{fold_num}.pt\"\n\n# configuring the training job\nbatch_size = 128\nnum_epochs = 20\nsteps_per_epoch = 17118 // batch_size\nnum_classes = 5\n\noptimizer = \"adamw\"\nscheduler = \"onecyclelr\"\nlearning_rate = 0.002\nweight_decay = 0.001\ngradient_clip = 0.1\n\n# custom parameters to override the default configs\ncustoms = [\n    f\"model={model_arch}\",\n    f\"optimizer={optimizer}\", \n    f\"scheduler={scheduler}\",\n    f\"image_dir={image_dir}\",\n    f\"csv_dir={csv_dir}\",\n    f\"json_dir={json_dir}\",\n    f\"fold_csv_dir={fold_csv_dir}\",\n    f\"fold_num={fold_num}\",\n    f\"run_name={run_name}\",\n    f\"checkpoint_path={checkpoint_path}\",\n    f\"model_save_dir={model_save_dir}\",\n]","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initializing Hydra Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from : https://github.com/facebookresearch/hydra/blob/master/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\nwith initialize_config_dir(config_dir=config_dir):\n    # override defaults with customs list\n    cfg = compose(config_name=config_name, overrides=customs)\n    \n    # overide with custom training configuration\n    cfg.training.num_epochs  = num_epochs\n    cfg.training.num_classes = num_classes\n    cfg.training.lr = learning_rate\n    cfg.training.steps_per_epoch = steps_per_epoch\n    cfg.optimizer.params.weight_decay = weight_decay\n    cfg.lightning.init_args.gradient_clip_val = gradient_clip\n    cfg.model.use_custom_base = True\n    \n    # display configuration\n    print(OmegaConf.to_yaml(cfg))","execution_count":5,"outputs":[{"output_type":"stream","text":"image_dir: /kaggle/input/cassava-leaf-disease-classification/train_images/\ncsv_dir: /kaggle/input/cassava-leaf-disease-classification/train.csv\njson_dir: /kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json\nfold_csv_dir: /kaggle/working/leaf-disease-classification-kaggle/data/fold_df.csv\nuse_weights: true\nfold_num: 0\nrun_name: efficientnetb0_fold_0_1606139094\ncheckpoint_path: /kaggle/working/\nmodel_save_dir: /kaggle/working/efficientnetb0_fold_0.pt\nseed: 42\nmodel:\n  class_name: timm.create_model\n  params:\n    pretrained: true\n    model_name: tf_efficientnet_b0\n  output_dims: 1000\n  fc1: 512\n  fc2: 256\n  num_classes: ${training.num_classes}\n  use_custom_base: true\ntraining:\n  seed: ${seed}\n  job_name: ${run_name}\n  checkpoint_path: ${checkpoint_path}\n  model_save_dir: ${model_save_dir}\n  num_epochs: 20\n  steps_per_epoch: 133\n  lr: 0.002\n  num_classes: 5\n  image_dim: 224\n  metric: val_loss\n  dataloaders:\n    batch_size: 128\n    pin_memory: true\n    num_workers: 5\nlightning:\n  callbacks:\n  - class_name: pytorch_lightning.callbacks.LearningRateMonitor\n    params:\n      logging_interval: step\n  - class_name: pytorch_lightning.callbacks.EarlyStopping\n    params:\n      monitor: ${training.metric}\n      patience: 5\n      mode: min\n  model_checkpoint:\n    filepath: ${training.checkpoint_path}\n    monitor: ${training.metric}\n    mode: min\n    save_top_k: 1\n  init_args:\n    precision: 16\n    gpus: 1\n    log_every_n_steps: 10\n    max_epochs: ${training.num_epochs}\n    benchmark: true\n    gradient_clip_val: 0.1\noptimizer:\n  class_name: torch.optim.AdamW\n  params:\n    lr: ${training.lr}\n    weight_decay: 0.001\nscheduler:\n  class_name: torch.optim.lr_scheduler.OneCycleLR\n  params:\n    max_lr: ${training.lr}\n    anneal_strategy: cos\n    cycle_momentum: true\n    epochs: ${training.num_epochs}\n    steps_per_epoch: ${training.steps_per_epoch}\n  interval: step\n  frequency: 1\n  monitor: null\nlogger:\n  api: a74f67fd5fae293e301ea8b6710ee0241f595a63\n  project: kaggle-leaf-disease\n  run_name: ${training.job_name}\n  class_name: pytorch_lightning.loggers.WandbLogger\n  params:\n    project: ${logger.project}\n    name: ${logger.run_name}\naugmentation:\n  train_augs:\n  - class_name: albumentations.RandomResizedCrop\n    params:\n      height: ${training.image_dim}\n      width: ${training.image_dim}\n      p: 1.0\n  - class_name: albumentations.Transpose\n    params:\n      p: 0.5\n  - class_name: albumentations.HorizontalFlip\n    params:\n      p: 0.5\n  - class_name: albumentations.RandomBrightnessContrast\n    params:\n      p: 0.5\n  - class_name: albumentations.ShiftScaleRotate\n    params:\n      p: 0.5\n  - class_name: albumentations.Normalize\n    params:\n      max_pixel_value: 255.0\n      p: 1.0\n  - class_name: albumentations.CoarseDropout\n    params:\n      p: 0.5\n  - class_name: albumentations.Cutout\n    params:\n      p: 0.5\n  - class_name: albumentations.pytorch.transforms.ToTensorV2\n    params:\n      p: 1.0\n  valid_augs:\n  - class_name: albumentations.Resize\n    params:\n      height: ${training.image_dim}\n      width: ${training.image_dim}\n      p: 1.0\n  - class_name: albumentations.Normalize\n    params:\n      max_pixel_value: 255.0\n      p: 1.0\n  - class_name: albumentations.pytorch.transforms.ToTensorV2\n    params:\n      p: 1.0\n  test_augs:\n  - class_name: albumentations.Resize\n    params:\n      height: ${training.image_dim}\n      width: ${training.image_dim}\n      p: 1.0\n  - class_name: albumentations.Normalize\n    params:\n      max_pixel_value: 255.0\n      p: 1.0\n  - class_name: albumentations.pytorch.transforms.ToTensorV2\n    params:\n      p: 1.0\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Run Training Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train model\nrun(cfg, print_layers=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}