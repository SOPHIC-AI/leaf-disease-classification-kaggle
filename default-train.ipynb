{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setup the kaggle environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!git clone https://github.com/benihime91/leaf-disease-classification-kaggle.git\n!pip install hydra-core timm --upgrade --quiet\n!apt install tree\n\nimport sys\nsys.path.append(\"/kaggle/working/leaf-disease-classification-kaggle/\")","execution_count":2,"outputs":[{"output_type":"stream","text":"Cloning into 'leaf-disease-classification-kaggle'...\nremote: Enumerating objects: 273, done.\u001b[K\nremote: Counting objects: 100% (273/273), done.\u001b[K\nremote: Compressing objects: 100% (191/191), done.\u001b[K\nremote: Total 273 (delta 132), reused 188 (delta 64), pack-reused 0\u001b[K\nReceiving objects: 100% (273/273), 8.38 MiB | 10.44 MiB/s, done.\nResolving deltas: 100% (132/132), done.\n/bin/sh: 1: sudo: not found\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Import depedencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom experiment import run\nfrom hydra.experimental import initialize, initialize_config_module, initialize_config_dir, compose\nfrom omegaconf import OmegaConf\nimport time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setting up the config pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting up config paths\nconfig_dir = \"/kaggle/working/leaf-disease-classification-kaggle/conf/\"\nconfig_name = \"config\"\nmodel_arch = \"resnext50_32x4d\"\n# which fold to train on ?\nfold_num = 0 \n\n# setting up the configuration\n# see: https://hydra.cc/docs/next/advanced/override_grammar/basic/\nimage_dir = \"/kaggle/input/cassava-leaf-disease-classification/train_images/\"\ncsv_dir   = \"/kaggle/input/cassava-leaf-disease-classification/train.csv\"\njson_dir  = \"/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json\"\nfold_csv_dir = \"/kaggle/working/leaf-disease-classification-kaggle/data/fold_df.csv\"\nrun_name = f\"{model_arch}_{fold_num}_{int(time.time())}\"\ncheckpoint_path = \"/kaggle/working/\"\nmodel_save_dir = f\"/kaggle/working/weights_stage2_fold_{fold_num}.pt\"\noptimizer = \"adamw\"\nscheduler = \"reducelronplateau\"\n\n\n# configuring the training job\nlearning_rate = 0.02\nweight_decay = 0.01\nnum_epochs = 20\nnum_classes = 5\n# train_lenght = 17118\n\n# custom parameters to override the default configs\ncustoms = [\n    f\"model={model_arch}\"\n    f\"optimizer={optimizer}\", \n    f\"scheduler={scheduler}\",\n    f\"image_dir={image_dir}\",\n    f\"csv_dir={csv_dir}\",\n    f\"json_dir={json_dir}\",\n    f\"fold_csv_dir={fold_csv_dir}\",\n    f\"fold_num={fold_num}\",\n    f\"run_name={run_name}\",\n    f\"checkpoint_path={checkpoint_path}\",\n    f\"model_save_dir={model_save_dir}\",\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Config Structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"!tree \"/kaggle/working/leaf-disease-classification-kaggle/conf/\"","execution_count":7,"outputs":[{"output_type":"stream","text":"\u001b[01;34m/kaggle/working/leaf-disease-classification-kaggle/conf/\u001b[00m\r\n├── \u001b[01;34maugmentation\u001b[00m\r\n│   └── augs.yaml\r\n├── config.yaml\r\n├── \u001b[01;34mlightning\u001b[00m\r\n│   └── default.yaml\r\n├── \u001b[01;34mlogger\u001b[00m\r\n│   └── wandb.yaml\r\n├── \u001b[01;34mmodel\u001b[00m\r\n│   ├── efficientnetb0.yaml\r\n│   ├── resnet50.yaml\r\n│   └── resnext50_32x4d.yaml\r\n├── \u001b[01;34moptimizer\u001b[00m\r\n│   ├── adam.yaml\r\n│   ├── adamw.yaml\r\n│   └── sgd.yaml\r\n├── \u001b[01;34mscheduler\u001b[00m\r\n│   ├── cosineannealingwarmrestarts.yaml\r\n│   ├── onecyclelr.yaml\r\n│   └── reducelronplateau.yaml\r\n└── \u001b[01;34mtraining\u001b[00m\r\n    └── default.yaml\r\n\r\n7 directories, 14 files\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Initializing Hydra & Run Training Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == \"__main__\":\n    # from : https://github.com/facebookresearch/hydra/blob/master/examples/jupyter_notebooks/compose_configs_in_notebook.ipynb\n    with initialize_config_dir(config_dir=config_dir):\n        # override defaults\n        cfg = compose(config_name=config_name, overrides=customs)\n        \n        # overide with custom training configuration\n        cfg.training.num_epochs  = num_epochs\n        cfg.training.num_classes = num_classes\n        cfg.training.lr = learning_rate\n        cfg.optimizer.params.weight_decay = weight_decay\n        \n        # train model\n        run(cfg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}