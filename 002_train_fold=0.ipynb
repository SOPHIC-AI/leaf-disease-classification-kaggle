{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "002-train-fold=0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1x3ZnMTkBTekrgbrU-zKV_GSB2-4ON6mb",
      "authorship_tag": "ABX9TyPOjZ9S2iP35z5ESqgRUdoM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benihime91/leaf-disease-classification-kaggle/blob/main/002_train_fold%3D0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otMVCQNNQ4mO"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR3Ri7_uvmJ1"
      },
      "source": [
        "# setup\n",
        "!pip install pytorch-lightning --quiet\n",
        "!pip install --upgrade albumentations wandb --quiet\n",
        "!git clone https://github.com/benihime91/leaf-disease-classification-kaggle.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mtwLGhcv9uL"
      },
      "source": [
        "! unzip -qq \"/content/drive/MyDrive/cassava-leaf-disease-classification.zip\" -d \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlKPGbFqxCk9"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "os.chdir(\"/content/leaf-disease-classification-kaggle/\")\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqtky2cXxaV1"
      },
      "source": [
        "# --------------------------------\n",
        "# IMPORT LIBRARIES\n",
        "# --------------------------------\n",
        "import pytorch_lightning as pl\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torchvision\n",
        "import logging\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import wandb\n",
        "\n",
        "from lightning import LightningModel_resnext50_32x4d as LitModel\n",
        "from lightning import LitDatatModule\n",
        "from preprocess import Preprocessor\n",
        "\n",
        "# set random seeds\n",
        "random.seed(42)\n",
        "pl.seed_everything(42)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "# set up paths to the data directories\n",
        "image_dir = \"/content/cassava-leaf-disease-classification/train_images\"\n",
        "csv_dir   = \"/content/cassava-leaf-disease-classification/train.csv\"\n",
        "json_dir  = \"/content/cassava-leaf-disease-classification/label_num_to_disease_map.json\"\n",
        "\n",
        "# login to wandb: a74f67fd5fae293e301ea8b6710ee0241f595a63\n",
        "wandb.login(key=\"a74f67fd5fae293e301ea8b6710ee0241f595a63\")\n",
        "# !wandb login \"a74f67fd5fae293e301ea8b6710ee0241f595a63\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XyuWrcPHUwL"
      },
      "source": [
        "os.chdir(\"/content/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnzfwuJ2yE5-"
      },
      "source": [
        "# # Run this cell for 1st time run\n",
        "# processor = Preprocessor(csv_dir, json_dir, image_dir, num_folds=5)\n",
        "# processor._shuffle_and_create_folds()\n",
        "# dataframe = processor.dataframe\n",
        "# dataframe.to_csv(\"/content/fold_df.csv\", index=False)\n",
        "# dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6v2WKT4ySYy"
      },
      "source": [
        "# since we already have the fold dataset\n",
        "fold_csv = \"/content/leaf-disease-classification-kaggle/fold_df.csv\"\n",
        "processor = Preprocessor(csv_dir, json_dir, image_dir, num_folds=5)\n",
        "# set the dataframe of Preprocessor to the the fold_csv\n",
        "processor.dataframe = pd.read_csv(fold_csv)\n",
        "processor.dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IpbQMYGycTa"
      },
      "source": [
        "# -------------------------------\n",
        "# Grab one FOLD\n",
        "# -------------------------------\n",
        "fold_num = 0\n",
        "trainFold, valFold = processor.get_fold(fold_num)\n",
        "testFold, valFold  = train_test_split(valFold, stratify=valFold.label, test_size=0.5) \n",
        "\n",
        "trainFold.reset_index(drop=True, inplace=True)\n",
        "testFold.reset_index(drop=True, inplace=True)\n",
        "valFold.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIhsVOadzTi7"
      },
      "source": [
        "print(\"Length of train data:\", len(trainFold))\n",
        "print(\"Length of test data:\", len(testFold))\n",
        "print(\"Length of valid data:\", len(valFold))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY9xMCS4zmS5"
      },
      "source": [
        "weights = processor.weights\n",
        "weights = torch.tensor(list(weights.values()))\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN3bH1iyzzCD"
      },
      "source": [
        "label_map = processor.label_map\n",
        "label_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygdIUtF82Yf6"
      },
      "source": [
        "def imshow(image, targets):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    grid = torchvision.utils.make_grid(images, normalize=True, nrow=4).permute(1, 2, 0).data.numpy()\n",
        "    grid = np.array(grid * 255., dtype=np.uint)\n",
        "    classes = targets.data.numpy()\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(grid)\n",
        "    plt.title([label_map[i] for i in classes]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPAj69ZG0KAp"
      },
      "source": [
        "image_dim = 224 # dimension of the image after resize\n",
        "\n",
        "# Specify TRANSFORATIONS for TRAIN/VAL/TEST DATALOADERS\n",
        "train_transformations = A.Compose([\n",
        "    A.Rotate(p=0.5, limit=60),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.CLAHE(p=0.5),\n",
        "    A.OneOf([A.RandomFog(), A.RandomRain(), A.RandomSnow()]),\n",
        "    A.ShiftScaleRotate(p=0.5),\n",
        "    A.RandomResizedCrop(image_dim, image_dim, always_apply=True),\n",
        "    A.Normalize(always_apply=True),\n",
        "    ToTensorV2(always_apply=True),\n",
        "\n",
        "])\n",
        "\n",
        "valid_transformations = A.Compose([\n",
        "    A.Resize(image_dim, image_dim, always_apply=True),\n",
        "    A.Normalize(always_apply=True),\n",
        "    ToTensorV2(always_apply=True)\n",
        "])\n",
        "\n",
        "test_transformations = valid_transformations\n",
        "\n",
        "albu_transforms = {\n",
        "    \"train\": train_transformations, \n",
        "    \"valid\": valid_transformations,\n",
        "    \"test\" : test_transformations,\n",
        "}\n",
        "\n",
        "# Generate LIGHTNING-DATAMODULE\n",
        "batch_size = 64\n",
        "data_module = LitDatatModule(trainFold, valFold, testFold, batch_size, albu_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwyHFmbb1QDC"
      },
      "source": [
        "# -----------------------------------\n",
        "# GENERATE TRAIN/VAL/TEST DATLOADERS\n",
        "# ------------------------------------\n",
        "data_module.setup()\n",
        "train_dl = data_module.train_dataloader()\n",
        "val_dl = data_module.val_dataloader()\n",
        "test_dl = data_module.test_dataloader()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-hcruqh1aNN"
      },
      "source": [
        "# TRAIN DATALOADER\n",
        "batch = next(iter(train_dl))\n",
        "images, targets = batch\n",
        "example_input_array = images # needed to log graph to logger\n",
        "images  = images[:4]\n",
        "targets = targets[:4]\n",
        "# view images from the DATALOADER\n",
        "imshow(images, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bRr--pJ1j0S"
      },
      "source": [
        "# VALID DATALOADER\n",
        "batch = next(iter(val_dl))\n",
        "images, targets = batch\n",
        "val_samples = batch\n",
        "images  = images[:4]\n",
        "targets = targets[:4]\n",
        "# view images from the DATALOADER\n",
        "imshow(images, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc8gZXmr2ezf"
      },
      "source": [
        "# TEST DATALOADER\n",
        "batch = next(iter(test_dl))\n",
        "images, targets = batch\n",
        "images  = images[:4]\n",
        "targets = targets[:4]\n",
        "# view images from the DATALOADER\n",
        "imshow(images, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXj5nlrHB2H7"
      },
      "source": [
        "class ImagePredsModelLogger(pl.Callback):\n",
        "    def __init__(self, val_samples, num_samples=batch_size):\n",
        "        \"\"\"\n",
        "        Upon validation_epoch_end log num_samples images \n",
        "        and their predictions to wandb\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.val_imgs, self.val_labels = val_samples\n",
        "        self.val_imgs = self.val_imgs[:num_samples]\n",
        "        self.val_labels = self.val_labels[:num_samples]\n",
        "          \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
        "\n",
        "        logits = pl_module(val_imgs)\n",
        "        preds = torch.argmax(logits, -1)\n",
        "\n",
        "        trainer.logger.experiment.log({\n",
        "            \"examples\": [wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") for x, pred, y in zip(val_imgs, preds, self.val_labels)],\n",
        "            \"global_step\": trainer.global_step\n",
        "            })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5aSPEG42gQE"
      },
      "source": [
        "# ----------------------------------\n",
        "# TRAINING ARGUMENTS\n",
        "# ------------------------------------\n",
        "num_epochs = 15\n",
        "steps_per_epoch = len(train_dl)\n",
        "total_steps = num_epochs * steps_per_epoch\n",
        "\n",
        "learning_rate = 3e-04\n",
        "weight_decay = 0.001\n",
        "\n",
        "output_dims = len(label_map)\n",
        "\n",
        "# Parse arguments\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=learning_rate, help=\"AdamW: learning rate\")\n",
        "parser.add_argument(\"--weight_decay\", type=float, default=weight_decay, help=\"AdamW: weight_decay\")\n",
        "parser.add_argument(\"--total_steps\", type=int, default=total_steps, help=\"total steps to train for\")\n",
        "parser.add_argument(\"--output_dims\", type=int, default=output_dims, help=\"number of output classes\")\n",
        "args, _ = parser.parse_known_args()\n",
        "\n",
        "logger = logging.getLogger(\"lightning\")\n",
        "logger.info(f\"num_epochs: {num_epochs}\")\n",
        "logger.info(f\"steps_per_epoch: {steps_per_epoch}\")\n",
        "logger.info(f\"total_steps: {total_steps}\")\n",
        "logger.info(f\"learning_rate: {learning_rate}\")\n",
        "logger.info(f\"weight_decay: {weight_decay}\")\n",
        "logger.info(f\"output_dims: {output_dims}\")\n",
        "\n",
        "# -----------------------------------\n",
        "# LIGHTNING TRAINER\n",
        "# ------------------------------------\n",
        "\n",
        "# Init trainer callbacks\n",
        "PATH = \"/content/drive/MyDrive/modelCheckpoint\"\n",
        "os.makedirs(PATH, exist_ok=True)\n",
        "model_checkpoint = pl.callbacks.ModelCheckpoint(filepath=PATH, monitor=\"val_loss\", save_top_k=1, mode=\"min\")\n",
        "\n",
        "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n",
        "\n",
        "run_name = \"fold=0\"\n",
        "wb_logger = pl.loggers.WandbLogger(project=\"kaggle-leaf-disease\", name=run_name)\n",
        "wb_logger.log_hyperparams(vars(args))\n",
        "\n",
        "\n",
        "callbacks = [lr_monitor, ImagePredsModelLogger(val_samples), stopping]\n",
        "\n",
        "# Init trainer\n",
        "trainer = pl.Trainer(\n",
        "    precision=16, \n",
        "    gpus=-1, \n",
        "    logger=wb_logger,\n",
        "    checkpoint_callback=model_checkpoint, \n",
        "    callbacks=callbacks, \n",
        "    max_epochs=num_epochs, \n",
        "    max_steps=total_steps,\n",
        "    gradient_clip_val=0.1,\n",
        "    benchmark=True,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwOuPHvH2zHf"
      },
      "source": [
        "# -------------------------------\n",
        "# INSTANTIATE AND FIT MODEL  :\n",
        "# --------------------------------\n",
        "\n",
        "# Init DataModule\n",
        "batch_size = 64\n",
        "data_module = LitDatatModule(trainFold, valFold, testFold, batch_size, albu_transforms)\n",
        "\n",
        "# Init model\n",
        "model = LitModel(**vars(args), class_weights=weights)\n",
        "model.example_input_array = torch.zeros_like(example_input_array)\n",
        "\n",
        "# Freeze the feature extractor/base of the model\n",
        "model.freeze_classifier()\n",
        "\n",
        "# Log model topology \n",
        "wb_logger.watch(model.net)\n",
        "\n",
        "# Pass the datamodule as arg to trainer.fit to override model hooks :)\n",
        "trainer.fit(model, datamodule=data_module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYFL6YPLDEIc"
      },
      "source": [
        "# Compute metrics on test dataset\n",
        "trainer.test(model, datamodule=data_module)\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUejJi686t4p"
      },
      "source": [
        "torchmodel = model.net\n",
        "# save torch model state dict\n",
        "torch.save(torch.model.state_dict(), f\"/content/modelWeights-Fold={fold_num}.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}