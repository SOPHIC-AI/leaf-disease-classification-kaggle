{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PR3Ri7_uvmJ1"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning wandb --upgrade --quiet\n",
    "!git clone https://github.com/benihime91/leaf-disease-classification-kaggle.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlKPGbFqxCk9"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.chdir(\"/kaggle/working/leaf-disease-classification-kaggle/\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqtky2cXxaV1"
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Import Libraries\n",
    "# -----------------------\n",
    "import pytorch_lightning as pl\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "import logging\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import time\n",
    "\n",
    "from lightning import LightningModel_resnext50_32x4d as LitModel\n",
    "from lightning import LitDatatModule\n",
    "from preprocess import Preprocessor\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# set up paths to the data directories\n",
    "image_dir = \"/kaggle/input/cassava-leaf-disease-classification/train_images\"\n",
    "csv_dir   = \"/kaggle/input/cassava-leaf-disease-classification/train.csv\"\n",
    "json_dir  = \"/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json\"\n",
    "\n",
    "# set random seeds\n",
    "random.seed(42)\n",
    "pl.seed_everything(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# login to wandb: a74f67fd5fae293e301ea8b6710ee0241f595a63\n",
    "! wandb login \"a74f67fd5fae293e301ea8b6710ee0241f595a63\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate train/validation/test data corresponding to the particular fold number, after which we will instantiate the `LightningDataModule` class to generate our dataloaders for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6v2WKT4ySYy"
   },
   "outputs": [],
   "source": [
    "# since we already have the fold dataset\n",
    "fold_csv = \"/kaggle/working/leaf-disease-classification-kaggle/fold_df.csv\"\n",
    "processor = Preprocessor(csv_dir, json_dir, image_dir, num_folds=5)\n",
    "# set the dataframe of Preprocessor to the the fold_csv\n",
    "df = pd.read_csv(fold_csv)\n",
    "df.filePath = [os.path.join(image_dir, df.image_id[i]) for i in range(len(df))]\n",
    "processor.dataframe = df\n",
    "processor.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IpbQMYGycTa"
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Grab one FOLD\n",
    "# -------------------------------\n",
    "\n",
    "fold_num = 0 # specify the number of the fold\n",
    "\n",
    "trainFold, valFold = processor.get_fold(fold_num)\n",
    "testFold, valFold  = train_test_split(valFold, stratify=valFold.label, test_size=0.5) \n",
    "\n",
    "trainFold.reset_index(drop=True, inplace=True)\n",
    "testFold.reset_index(drop=True, inplace=True)\n",
    "valFold.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIhsVOadzTi7"
   },
   "outputs": [],
   "source": [
    "print(\"Length of train data:\", len(trainFold))\n",
    "print(\"Length of test data:\",  len(testFold))\n",
    "print(\"Length of valid data:\", len(valFold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZY9xMCS4zmS5"
   },
   "outputs": [],
   "source": [
    "weights = processor.weights\n",
    "weights = torch.tensor(list(weights.values()))\n",
    "weights = 1 - weights\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IN3bH1iyzzCD"
   },
   "outputs": [],
   "source": [
    "label_map = processor.label_map\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygdIUtF82Yf6"
   },
   "outputs": [],
   "source": [
    "def imshow(image, targets):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    grid = torchvision.utils.make_grid(image, normalize=True, nrow=4).permute(1, 2, 0).data.numpy()\n",
    "    grid = np.array(grid * 255., dtype=np.uint)\n",
    "    classes = targets.data.numpy()\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(grid)\n",
    "    plt.title([label_map[i] for i in classes]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify transformations for train/valid/test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPAj69ZG0KAp"
   },
   "outputs": [],
   "source": [
    "image_dim = 224 # dimension of the image after resize\n",
    "\n",
    "# Specify TRANSFORATIONS for TRAIN/VAL/TEST DATALOADERS\n",
    "train_transformations = A.Compose([\n",
    "    A.RandomResizedCrop(image_dim, image_dim, p=1.0),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.Resize(image_dim, image_dim, always_apply=True),\n",
    "    A.Normalize(max_pixel_value=255.0, p=1.0),\n",
    "    A.CoarseDropout(p=0.5),\n",
    "    A.Cutout(p=0.5),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "valid_transformations = A.Compose([\n",
    "    A.Resize(image_dim, image_dim, always_apply=True),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0)\n",
    "])\n",
    "\n",
    "test_transformations = valid_transformations\n",
    "\n",
    "albu_transforms = {\n",
    "    \"train\": train_transformations, \n",
    "    \"valid\": valid_transformations,\n",
    "    \"test\" : test_transformations,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**instantiate `LightningDataModule`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "dm = LitDatatModule(trainFold, valFold, testFold, batch_size, albu_transforms, num_workers=5, pin_memory=True)\n",
    "dm.setup()\n",
    "\n",
    "# grab samples to log predictions on\n",
    "samples = next(iter(dm.val_dataloader()))\n",
    "\n",
    "# view sample images\n",
    "ims, targs = next(iter(dm.train_dataloader()))\n",
    "imshow(ims[:4], targs[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the training configuration and initiate the `Trainer` class from pytorch-lightning to train our `LightningModule` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# TRAINING ARGUMENTS\n",
    "# ----------------------------------\n",
    "num_epochs = 20\n",
    "steps_per_epoch = len(dm.train_dataloader())\n",
    "total_steps = num_epochs * steps_per_epoch\n",
    "\n",
    "learning_rate = 0.01\n",
    "weight_decay = 0.00001\n",
    "\n",
    "output_dims = len(label_map)\n",
    "\n",
    "# Parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=learning_rate, help=\"learning rate\")\n",
    "parser.add_argument(\"--weight_decay\",  type=float, default=weight_decay, help=\"weight_decay\")\n",
    "parser.add_argument(\"--total_steps\",   type=int, default=total_steps, help=\"total steps to train for\")\n",
    "parser.add_argument(\"--output_dims\",   type=int, default=output_dims, help=\"number of output classes\")\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "logger = logging.getLogger(\"lightning\")\n",
    "logger.info(f\"num_epochs: {num_epochs}\")\n",
    "logger.info(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "logger.info(f\"total_steps: {total_steps}\")\n",
    "logger.info(f\"learning_rate: {learning_rate}\")\n",
    "logger.info(f\"weight_decay: {weight_decay}\")\n",
    "logger.info(f\"output_dims: {output_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePredictionLogger(pl.Callback):\n",
    "    def __init__(self, val_samples, num_samples = 32):\n",
    "        \"\"\"\n",
    "        Upon finishing training log num_samples number\n",
    "        of images and their predictions to wandb\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.val_imgs, self.val_labels = val_samples\n",
    "        self.val_imgs   = self.val_imgs[:num_samples]\n",
    "        self.val_labels = self.val_labels[:num_samples]\n",
    "          \n",
    "    def on_fit_end(self, trainer, pl_module):\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)\n",
    "        examples = [wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") for x, pred, y in zip(val_imgs, preds, self.val_labels)]\n",
    "        trainer.logger.experiment.log({\"examples\": examples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5aSPEG42gQE"
   },
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# LIGHTNING TRAINER\n",
    "# ------------------------------------\n",
    "# init model-checkpoint callback for lightning trainer\n",
    "PATH = \"/kaggle/working/\"\n",
    "chkpt = pl.callbacks.ModelCheckpoint(filepath=PATH, monitor=\"val_loss\", save_top_k=1, mode=\"min\")\n",
    "\n",
    "# init learning-rate monitor to track learning rates\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "# init wandb logger for pytorch-lightning\n",
    "run_name = f\"resnext50_32x4d|fold={fold_num}|{time.strftime('%H:%M:%S-%Y/%m/%d')}\"\n",
    "wb_logger = pl.loggers.WandbLogger(project=\"kaggle-leaf-disease\", name=run_name)\n",
    "\n",
    "# init early stopping callback\n",
    "stopping = pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, mode=\"min\")\n",
    "\n",
    "# convert all callbacks to a list\n",
    "cbs = [lr_monitor, ImagePredictionLogger(samples), stopping]\n",
    "\n",
    "# Init trainer\n",
    "trainer = pl.Trainer(\n",
    "    precision=16,\n",
    "    gpus=1,\n",
    "    logger=wb_logger,\n",
    "    checkpoint_callback=chkpt,\n",
    "    callbacks=cbs,\n",
    "    max_steps=total_steps,\n",
    "    log_every_n_steps=10,\n",
    ")\n",
    "\n",
    "# log the training config to wandb\n",
    "wb_logger.log_hyperparams(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we instantiate the `LightningModule` model specified in `lightning.py` script. We will then log the model architecture to wandb and use `pytorch-lightning` `Trainer` to train/validate and test the model upon whose completion we will save the weights of the pytorch-model wrapped under the `LightningModule` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init LightningModule\n",
    "hidden_dims = 512\n",
    "model = LitModel(**vars(args), hidden_dims=hidden_dims, class_weights=None)\n",
    "model.example_input_array = torch.zeros_like(ims)\n",
    "\n",
    "# freeze/unfreeze the feature extractor of the model\n",
    "model.unfreeze_classifier()\n",
    "\n",
    "# log model topology to wandb\n",
    "wb_logger.watch(model.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the datamodule as arg to trainer.fit to override model hooks :)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYFL6YPLDEIc"
   },
   "outputs": [],
   "source": [
    "# Compute metrics on test dataset\n",
    "_ = trainer.test(model, datamodule=dm, ckpt_path=chkpt.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUejJi686t4p"
   },
   "outputs": [],
   "source": [
    "PATH = chkpt.best_model_path # path to the best performing model\n",
    "WEIGHTS_PATH = f\"/kaggle/working/weights_fold={fold_num}.pt\"\n",
    "\n",
    "loaded_model = model.load_from_checkpoint(checkpoint_path=chkpt.best_model_path, **vars(args))\n",
    "torchmodel = loaded_model.net\n",
    "\n",
    "# save torch model state dict\n",
    "torch.save(torchmodel.state_dict(), WEIGHTS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the saved files :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "class TransferLearningModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The base for the lightning model\n",
    "    \"\"\"\n",
    "    def __init__(self, classifier: nn.Module, base: nn.Module):\n",
    "        super(TransferLearningModel, self).__init__()\n",
    "        # Set our init args as class attributes\n",
    "        self.classifier = classifier\n",
    "        self.base = base\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.base(self.classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble network\n",
    "classifier = models.resnext50_32x4d()\n",
    "\n",
    "# dims for the base model\n",
    "num_ftrs = classifier.fc.out_features\n",
    "h1 = 512 \n",
    "h2 = int(h1/2)\n",
    "\n",
    "base_model = nn.Sequential(\n",
    "    nn.BatchNorm1d(num_ftrs),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(num_ftrs, h1),\n",
    "    nn.BatchNorm1d(h1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(h1, h2),\n",
    "    nn.BatchNorm1d(h2),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(h2, 5)\n",
    ")\n",
    "\n",
    "# init model\n",
    "Net = TransferLearningModel(classifier, base_model)\n",
    "\n",
    "# load saved model weights\n",
    "state_dict = torch.load(WEIGHTS_PATH, map_location=device)\n",
    "# load the torch state dict to the model\n",
    "Net.load_state_dict(state_dict)\n",
    "logger.info(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weights to wandb\n",
    "# WandB – Save the model checkpoint. This automatically saves a file to the cloud and associates it with the current run.\n",
    "wandb.save(WEIGHTS_PATH)\n",
    "# finish run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
